---
title: "Final Project"
author: "Jerry Mischel"
date: "August 14, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Dataset
```{r}
#load dataset
setwd("C:/Users/jmmis/Documents/Data Science/DS 740 - Data Mining/Final Project/beer-recipes")
beer = read.csv("recipeData.csv", header=T)
```

## Initial Data Exploration and Investigation

```{r }

#reduce dataset to numerical variables and no NAs to investigate collinearity
beer_cor = beer[,c(6:16, 19:20)]
beer_cor2 = beer_cor[-which(beer_cor$BoilGravity=="N/A"),]
beer_cor2 = beer_cor2[-which(beer_cor2$PitchRate=="N/A"),]
beer_cor2 = beer_cor2[-which(beer_cor2$MashThickness=="N/A"),]
beer_cor2 = beer_cor2[-which(beer_cor2$PrimaryTemp=="N/A"),]
pairs(beer_cor2)

#create numeric variables
beer_cor2$BoilGravity = as.numeric(beer_cor2$BoilGravity)
beer_cor2$MashThickness = as.numeric(beer_cor2$MashThickness)
beer_cor2$PitchRate = as.numeric(beer_cor2$PitchRate)
beer_cor2$PrimaryTemp = as.numeric(beer_cor2$PrimaryTemp)

#investigate distributions -- a mix of normal and skewed distributions, some with many outliers
#need to investigate further with clean dataset
boxplot(beer_cor2$OG)
boxplot(beer_cor2FG)
boxplot(beer_cor2$ABV)
boxplot(beer_cor2$IBU)
boxplot(beer_cor2$Color)
boxplot(beer_cor2$BoilSize)
boxplot(beer_cor2$BoilTime)
boxplot(beer_cor2$Efficiency)
boxplot(beer_cor2$BoilGravity)
boxplot(beer_cor2$MashThickness)
boxplot(beer_cor2$PitchRate)
boxplot(beer_cor2$PrimaryTemp)

```

#Benchmark MSE with current formula
```{r}
#create new column with ABV estimates from standard formula
beer$ABVest = (beer$OG-beer$FG)*131.25

#find MSE value for ABV vs. ABVest
ABVest_mse = mean((beer$ABVest-beer$ABV)^2) 
ABVest_mse #57053.51 -- OG values are too high in places causing these deviances to be larger than expected; investigate further

#investigate distribution for OG
boxplot(beer$OG) #outliers higher than 5, OG's shouldn't be more than 2 according to brewing guides
#how many OG values are greater than 2? to get an accurate benchmark MSE to measure my models against, I'll need to remove these extreme outliers
length(which(beer$OG>2)) #1902

#further reading on beer websites revealed a difference in scaling between Plato and Specific Gravity sugar scales -- need to convert all measurements from plato scale to Specific Gravity
#use this formula - SG = 1 + (plato/(258.6 -((plato/258.2)*227.1)))

beer$OG[beer$SugarScale=="Plato"] = 1 + (beer$OG[which(beer$SugarScale=="Plato")]  /(258.6 -((beer$OG[which(beer$SugarScale=="Plato")]  /258.2)*227.1))) 
beer$FG[beer$SugarScale=="Plato"] = 1 + (beer$FG[which(beer$SugarScale=="Plato")]  /(258.6 -((beer$FG[which(beer$SugarScale=="Plato")]  /258.2)*227.1))) 
beer$ABVest = (beer$OG-beer$FG)*131.25

#to maintain consistency in scaling convert BoilGravity from Plato SugarScale to Specific Gravity SugarScale
beer$BoilGravity = as.numeric(as.character(beer$BoilGravity))
beer$BoilGravity[beer$SugarScale=="Plato"] = 1 + (beer$BoilGravity[which(beer$SugarScale=="Plato")]  /(258.6 -((beer$BoilGravity[which(beer$SugarScale=="Plato")]  /258.2)*227.1))) 

#remove one OG outlier which impacts overall MSE value (73575 observations)
#remove all ABVs less than 2, as some people entered values incorrectly
beer2 = beer[-which(beer$OG>2),]
beer2 = beer2[-which(beer2$ABV<2),]

#remove extreme outlier for OG
beer3 = beer2[-which.max(beer2$OG)]

#reevaluate MSE benchmark
ABVest_mse2 = mean((beer3$ABVest-beer3$ABV)^2); ABVest_mse2 #0.1019201, a more reasonable benchmark value from which to compare my models

```

## Data Preparation
```{r}
#select variables which could be used to make a prediction
#remove BeerID, Name, URL, Style, StyleID (too numerous), PrimingMethod (too many categories), PrimingAmount(too many categories), SugarScale (no longer needed given conversion), MashThickness (impacts brew method when NAs are removed)
#organize data better
beer_new = beer2[,c(9, 24, 6:8, 10:15, 18:20)]

#convert factors into numeric
beer_new$PrimaryTemp = as.numeric(as.character(beer_new$PrimaryTemp))
beer_new$PitchRate = as.numeric(as.character(beer_new$PitchRate))

#convert BrewMethod factors to numeric labels
beer_new$BrewMethod = as.character(beer_new$BrewMethod)
beer_new$BrewMethod[which(beer_new$BrewMethod=="All Grain")] = "1"
beer_new$BrewMethod[which(beer_new$BrewMethod=="BIAB")] = "2"
beer_new$BrewMethod[which(beer_new$BrewMethod=="extract")] = "3"
beer_new$BrewMethod[which(beer_new$BrewMethod=="Partial Mash")] = "4"

#change BrewMethod back to factor
beer_new$BrewMethod = as.factor(beer_new$BrewMethod)

#remove all NA's to generate complete dataset with no missing values
#this process removed more than 40k observations, which less than ideal, but I still have more than 31k left to build my models which seem sufficient
beer_new2 = na.omit(beer_new)

#recalculate MSE for ABV
ABVest_mse3 = mean((beer_new2$ABVest-beer_new2$ABV)^2); ABVest_mse3 #0.009985072
```

## Additional Data Exploration with clean dataset
```{r}
#shows relationships between all variables -- examine possible collinearity
pairs(beer_new2)

#examine distributions for all variables
boxplot(beer_new2$ABV)
hist(beer_new2$ABV)

boxplot(beer_new2$OG)
hist(beer_new2$OG)

boxplot(beer_new2FG)
hist(beer_new2FG)

boxplot(beer_new2$IBU)
hist(beer_new2$IBU)

boxplot(beer_new2$Color)
hist(beer_new2$Color)

boxplot(beer_new2$Size.L.)
hist(beer_new2$Size.L.)

boxplot(beer_new2$BoilSize)
hist(beer_new2$BoilSize)

boxplot(beer_new2$BoilTime)
hist(beer_new2$BoilTime)

boxplot(beer_new2$Efficiency)
hist(beer_new2$Efficiency)

boxplot(beer_new2$BoilGravity)
hist(beer_new2$BoilGravity)

boxplot(beer_new2$PitchRate)
hist(beer_new2$PitchRate)

boxplot(beer_new2$PrimaryTemp)
hist(beer_new2$PrimaryTemp)

```

## Multiple Linear Regression - Regsubsets

```{r }
#determine regsubsets variables to use in validation set assessment
library(leaps)
beer.reg = regsubsets(ABV~.-ABVest, data=beer_new2, nvmax=12)
plot(beer.reg)
#best model - ABV~OG+FG+BoilTime+PitchRate+PrimaryTemp

```

## Validation Set Assessment - Multilinear Regression, Decision Trees and ANNs

```{r}
###############################################################################################
##### Validation set assessment with inner loop for selection and outer set for assessment #####				 
###############################################################################################

#model list specification for multiple linear regression
nmodels = 13
Model1 = (ABV ~ Size.L.)
Model2 = (ABV ~ Size.L.+OG)
Model3 = (ABV ~ Size.L.+OG+FG)
Model4 = (ABV ~ Size.L.+OG+FG+IBU)
Model5 = (ABV ~ Size.L.+OG+FG+IBU+Color)
Model6 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize)
Model7 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize+BoilGravity)
Model8 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize+BoilGravity+Efficiency)
Model9 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize+BoilGravity+Efficiency+BrewMethod)
Model10 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize+BoilGravity+Efficiency+BrewMethod+PitchRate)
Model11 = (ABV ~ Size.L.+OG+FG+IBU+Color+BoilSize+BoilGravity+Efficiency+BrewMethod+PitchRate+PrimaryTemp)
Model12 = (ABV ~ OG+FG+BoilTime+PitchRate+PrimaryTemp) #regsubsets
Model13 = (ABV ~ OG+FG) #two most important variables

#storage for all models
all.lm.Models = list(Model1,Model2,Model3,Model4,Model5,Model6,Model7,
				 Model8,Model9,Model10,Model11,Model12, Model13)	

##### model assessment with inner entire model-fitting process (including cross-validation for model selection) #####
fulldata.out = beer_new2 #load in clean dataset
k.out = 10 #10-fold CV
n.out = dim(fulldata.out)[1]

#define the split into training set (79%) and testing set (21%)
trainn.out = 25000
testn.out = 6644
set.seed(111)
test.out = sample(1:n.out,testn.out)  #produces list of data to exclude
testinclude.out = is.element(1:n.out,test.out)  # sets up a T-F vector to be used similarly as group T-F vectors

#split the data into training and test sets
traindata.out = beer_new2[!testinclude.out,]
trainx.out = model.matrix(ABV~.,data=traindata.out)[,-(1:2)]
trainy.out = traindata.out[,1]
testdata.out = beer_new2[testinclude.out,]
testx.out = model.matrix(ABV~.,data=traindata.out)[,-(1:2)]
testy.out = testdata.out[,1]

  ### entire model-fitting process ###
  fulldata.in = traindata.out  # data going into model-fitting process
  x.in = model.matrix(ABV~.,data=traindata.out)[,-(1:2)]
  y.in = fulldata.in[,1]
  k.in = 10 
  n.in = dim(fulldata.in)[1]
  groups.in = rep(1:k.in,floor(n.in/k.in)) #create groups for cross-validation
  cvgroups.in = sample(groups.in,n.in)  #orders groups randomly, with seed (111)
  allbestmodels = rep(NA,5) #create repository for all bestmodels from different techiques
  
  #multilinear regression -- forward selection, regsubsets best and OG/FG
  all.lm.predictedCV.in = matrix(rep(NA,n.in*nmodels),ncol=nmodels) #create storage for all CV values
  for (i in 1:k.in)  {
    groupi.in = (cvgroups.in == i)
    for (m in 1:nmodels) {
      lmfitCV.in = lm(formula = all.lm.Models[[m]], data=beer_new2,subset=!groupi.in)
      all.lm.predictedCV.in[groupi.in,m] = predict.lm(lmfitCV.in, fulldata.in[groupi.in,])
    }
    
  }
    #place-holder and calculation for CVs from all multiple linear models
    all.lm.modelCV.in = rep(NA,nmodels) 
    for (m in 1:nmodels) { 
      all.lm.modelCV.in[m] = mean((all.lm.predictedCV.in[,m]-fulldata.in$ABV)^2)
  }
  
  bestlmmodel.in = (1:nmodels)[order(all.lm.modelCV.in)[1]] #defines best multilinear model
  bestlmmodelCV.in = min(all.lm.modelCV.in) # model selection by lowest MSE
  allbestmodels[1] = bestlmmodelCV.in #save best multiple linear model into best models vector
  
  ##Decision Trees -- Boosting
  #determine optimal parameters lambda and depth
  lambdalist.boost = 1:5/1000
  depthlist.boost = 1:5
  boost.results <- data.frame(rep(NA, 25), rep(lambdalist.boost, each=5), rep(depthlist.boost,5)) #storage for results
  colnames(boost.results) <- c('CV', 'Shrinkage', 'Depth')
  
  for (mmm in 1:25) {
    #perform boosting and predicted values
    beer.boost = gbm(ABV~.-ABVest, data=fulldata.in, distribution="gaussian", n.trees=1000, shrinkage=boost.results$Shrinkage[mmm], interaction.depth=boost.results$Depth[mmm])
    boost.results$CV[mmm] = mean((beer.boost$fit-fulldata.in$ABV)^2) #store CV values for each of 25 models
            }
  
  bestmodel.boost = boost.results[order(boost.results$CV)[1],] #save best parameters based on lowest CV value
  bestCV.boost = bestmodel.boost$CV #best CV value for boosting
  allbestmodels[2] = bestCV.boost #save best boosting model
  
  ##Decision Trees -- Bagging/Random Forest
  MSEall.bag = rep(0,12) #storage for MSE/CV values for 12 models; determine optimal number of variables to use at each split
  for (ii in 1:12) {
    #perform bagging 
    beer.bag = randomForest(ABV~.-ABVest, data=fulldata.in, ntree=250, mtry = ii, importance = T) #previous tests of this function show CV value level off after 250 trees
    MSEall.bag[ii]=beer.bag$mse[length(beer.bag$mse)] #save MSE values for all 12 models
    bestmodel.bag = order(MSEall.bag)[1]
    bestCV.bag = MSEall.bag[bestmodel.bag] #determine best MSE value
  }
  allbestmodels[3] = bestCV.bag #save best MSE value
  # [1] 0.63898817 0.26583656 0.15707204 0.10298781 0.06928646 0.05601945 0.04925625
  #[8] 0.04450721 0.03576210 0.03426844 0.03163261 0.03178753 -- best model (mtry=11)
  
  #Decision Trees -- Pruning
  mytree = tree(ABV~.-ABVest, data = fulldata.in) #create tree
  beer.cv = cv.tree(mytree, FUN=prune.tree) #run cross-validation
  beerCV <- min(beer.cv$dev) #find minimum dev value
  which(beer.cv$dev == min(beer.cv$dev))
  bestSize <- beer.cv$size[which(beer.cv$dev == min(beer.cv$dev))] #determine bestsize or best number of leaves (9)
  minBest <- min(bestSize)
  allbestmodels[4] = beerCV/nrow(fulldata.in) #save minimum CV value
  beer.prune = prune.tree(mytree, best=minBest)
        
  ##Artificial Neural Networks
  fulldata.in$BrewMethod = as.numeric(fulldata.in$BrewMethod) #switch back BrewMethod to numeric
  sizes=1:5 #test different number of hidden nodes
  decayRate = seq(.1, .5, by = .1) #test different decayRates
  ann.results = data.frame(rep(NA, 25), rep(sizes, each=5), rep(decayRate,5)) #storage for results
  colnames(ann.results) <- c('CV', 'Sizes', 'DecayRate')
  predictions = matrix( , nr = n, nc = length(sizes)*length(decayRate) ) #storage for prediction results
  ABV.group = matrix( , nr = n, nc = length(sizes)*length(decayRate) ) #storage for ABV values
  conv = matrix( , nr = k, nc = length(sizes)*length(decayRate)) #check if models converged
  
	#cross validation for loop
  for(i in 1:k){
	  groupi = (cvgroups == i) #split groups
	  beer.train = scale(fulldata.in[!groupi, 3:14]) #scale predictor variables
    beer.valid = scale(fulldata.in[groupi, 3:14], center = attr(beer.train, "scaled:center"), scale = attr(beer.train, "scaled:scale")) #scale predictor variables for test set
    beer.train = data.frame(ABV = fulldata.in[!groupi,1],beer.train)
    beer.valid = data.frame(ABV = fulldata.in[groupi,1],beer.valid)
	  #inner loop running through each size of nodes and decayRate
    for(j in 1:25){
		  ann.fit = nnet(ABV~., data = beer.train, size = ann.results$Sizes[j], decayRate=ann.results$DecayRate[j], maxit = 1000, linout = T, trace = F) 
		  predictions[groupi,j] = predict(ann.fit, beer.valid)
      ABV.group[groupi,j] = beer.valid[ ,1]
      conv[i, j] = ann.fit$convergence #most all models converged
	} # end iteration over j
} # end iteration over i

  #Choosing the Number of Hidden Nodes and DecayRate, based on minimum MSE value
  for (i in 1:25) {
    ann.results$CV[i] = mean((predictions[,i]-ABV.group[,i])^2)}
  bestmodel.ann = ann.results[order(ann.results$CV)[1],]
  bestMSE.ann = bestmodel.ann$CV
  allbestmodels[5] = bestMSE.ann #save best MSE model from ANN technique

##best model selections -- determine model with lowest MSE value
bestmodelCV = which.min(allbestmodels)

  #Run best model on validation (or test) dataset
  #Multiple Linear Regression -- forward selection, regsubsets, OG/FG
  if (bestmodelCV == 1)  {
    beer.train.lm = lm(all.lm.Models[[bestlmmodel.in]], data=traindata.out)
    predictvalid.final = predict(beer.train.lm, testdata.out)
  }
  
  #Decision Trees -- Boosting
  if (bestmodelCV == 2)  {
    beer.train.boost = gbm(ABV~.-ABVest, data=traindata.out, distribution="gaussian", n.trees=1000, shrinkage=bestmodel.boost$Shrinkage, interaction.depth=bestmodel.boost$Depth)
    predictvalid.final = predict(beer.train.boost, newdata=testdata.out, n.trees=1000)
  }
  
  #Decision Trees -- Bagging/Random Forest
  if (bestmodelCV == 3)  {
    beer.train.bag = randomForest(ABV~.-ABVest, data=traindata.out,mtry=bestmodel.bag, importance = T)
    predictvalid.final = predict(beer.train.bag, testdata.out)
  }
  
  #Decision Trees -- Pruning
  if (bestmodel == 4)  {
    beer.prune = prune.tree(mytree, best=minBest)
    predictvalid.final = predict(beer.prune, testdata.out)
  }

  #ANNs
  if (bestmodelCV == 5)  {
    traindata.out$BrewMethod = as.numeric(traindata.out$BrewMethod)
    testdata.out$BrewMethod = as.numeric((testdata.out$BrewMethod))
    beer.traindata.out.scale = scale(traindata.out[3:14])
    beer.testdata.out.scale = scale(testdata.out[3:14], center = attr(beer.traindata.out.scale, "scaled:center"), scale = attr(beer.traindata.out.scale, "scaled:scale"))
    beer.traindata.out.scale = data.frame(ABV = traindata.out[,1], beer.traindata.out.scale)
    beer.testdata.out.scale = data.frame(ABV = testdata.out[,1], beer.testdata.out.scale)
    beer.train.ann = nnet(ABV~., data=beer.traindata.out.scale, size=bestmodel.ann$Sizes, decayRate = bestmodel.ann$DecayRate, maxit = 1000, linout = T, trace = F)
    predictvalid.final = predict(beer.train.ann, beer.testdata.out.scale)
  }
  
##Best Model is multilinear regression, specifically regsubsets (ABV~OG+FG+BoilTime+PitchRate+PrimaryTemp) with a 0.0097 MSE rate
##Here's the model with coefficients (ABV = -1.678 + 131.5*OG - 129.9*FG + 0.000235*BoilTime + 0.007222*PitchRate + 0.0004571*PrimaryTemp)

#assessment on validation set yields an MSE value of 0.0096 and an R-squared value of 0.9972
Valid.out = sum((predictvalid.final-testy.out)^2)/testn.out; Valid.out
R2.out = 1-sum((predictvalid.final-testy.out)^2)/sum((testy.out-mean(testy.out))^2); R2.out

#plot relationship between predicted ABVs and actual ABVs
plot(predictvalid.final,testy.out)

#using final ANN model, which wasn't picked, wanted to find out most important variables
garson(beer.train.ann) #.41 importance for OG, and .10 for each BrewMethod and IBU

#using final bagging model, which also wasn't picked, to find most influential variables
importance(beer.bag) #OG (283.41) and FG (117.89) contribute the most significantly by far, followed by BoilGravity (3.14) and Color (2.57)
varImpPlot(beer.bag)
```  


